{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## Building a GPT\n",
    "\n",
    "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5hjCcLDr2WC"
   },
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"I visited Australia this year, a land of astonishing contrasts and spectacular beauty. \"\n",
    "    \"Amidst the vast, sun-drenched landscapes, I found myself mesmerized by the rich tapestry \"\n",
    "    \"of colors and textures. The azure skies stretched endlessly above, while the golden beaches \"\n",
    "    \"sparkled under the radiant sun. I explored the lush, verdant rainforests, teeming with vibrant \"\n",
    "    \"wildlife and exotic flora. The chorus of birdsong filled the air, creating a symphony of natural \"\n",
    "    \"sounds that was both enchanting and soothing.\"\n",
    "    \"In the heart of the country, I witnessed the majestic Uluru, a colossal red rock formation that rose \"\n",
    "    \"dramatically from the flat, arid desert. Its sheer size and deep, fiery hues were a breathtaking sight, \"\n",
    "    \"especially during sunset when the rock seemed to glow with an otherworldly light. The sacredness of \"\n",
    "    \"this ancient landmark was palpable, and I felt a profound sense of awe and respect for the indigenous \"\n",
    "    \"cultures that have revered it for millennia.\"\n",
    "    \"As I traveled along the rugged coastline, I encountered picturesque, azure bays and serene, turquoise \"\n",
    "    \"lagoons, each offering a unique and idyllic escape. The pristine, white sandy beaches were fringed with \"\n",
    "    \"swaying palm trees, and the crystal-clear waters invited me to dive into an underwater paradise. The Great \"\n",
    "    \"Barrier Reef, a kaleidoscopic wonderland of corals and marine life, was an unforgettable experience. The \"\n",
    "    \"myriad of colors and the graceful dance of the fish amidst the corals were a testament to the beauty and \"\n",
    "    \"fragility of our natural world.\"\n",
    "    \"In the bustling, cosmopolitan cities, I was captivated by the vibrant, multicultural atmosphere. Sydney, \"\n",
    "    \"with its iconic Opera House and stunning harbor, was a feast for the eyes. The city's architectural marvels \"\n",
    "    \"juxtaposed with the serene beauty of the botanical gardens created a harmonious blend of urban and natural \"\n",
    "    \"landscapes. Melbourne's art-filled laneways, brimming with creative energy, showcased the country's thriving \"\n",
    "    \"cultural scene. The aromatic scents of diverse cuisines wafted through the air, inviting me to indulge in a \"\n",
    "    \"culinary adventure.\"\n",
    "    \"The Australian wildlife was another highlight of my journey. From the adorable, cuddly koalas perched high in \"\n",
    "    \"the eucalyptus trees to the bounding kangaroos in the bushland, each encounter was a delightful surprise. The \"\n",
    "    \"vibrant, iridescent plumage of the parrots and the elusive, nocturnal wombat added to the enchantment of the \"\n",
    "    \"Australian fauna.\"\n",
    "    \"Throughout my travels, the warmth and friendliness of the Australian people were ever-present. Their laid-back, \"\n",
    "    \"welcoming nature made me feel at home in this distant land. The stories and laughter shared with locals enriched \"\n",
    "    \"my experience, leaving me with cherished memories and a deep appreciation for the diverse and captivating beauty of Australia.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xWI_VyAsN8F",
    "outputId": "0d0eb711-441e-4e13-ec36-eb22368ef219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  2773\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "20f2efad-1d53-4fc7-ed35-9757cf091696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I visited Australia this year, a land of astonishing contrasts and spectacular beauty. Amidst the va\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 100 characters\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "1f6c7e66-61bf-46d9-b80e-a020e72b002c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ',-.ABFGHIMORSTUabcdefghijklmnopqrstuvwxyz\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "dfbca5c0-325b-4fe5-e4ae-c032b9a875c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 26, 26, 1, 37, 25, 22, 35, 22]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "149df7a8-977e-4aca-a2a4-578fbbac06af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2773]) torch.int64\n",
      "tensor([11,  1, 39, 26, 36, 26, 37, 22, 21,  1,  6, 38, 36, 37, 35, 18, 29, 26,\n",
      "        18,  1, 37, 25, 26, 36,  1, 42, 22, 18, 35,  3,  1, 18,  1, 29, 18, 31,\n",
      "        21,  1, 32, 23,  1, 18, 36, 37, 32, 31, 26, 36, 25, 26, 31, 24,  1, 20,\n",
      "        32, 31, 37, 35, 18, 36, 37, 36,  1, 18, 31, 21,  1, 36, 33, 22, 20, 37,\n",
      "        18, 20, 38, 29, 18, 35,  1, 19, 22, 18, 38, 37, 42,  5,  1,  6, 30, 26,\n",
      "        21, 36, 37,  1, 37, 25, 22,  1, 39, 18])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100]) # the 100 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_WIXqxz0lU5"
   },
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD5Bj8Y6IAD4",
    "outputId": "905c50bb-753d-42c9-fb94-9408dcc4bc89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  1, 39, 26, 36, 26, 37, 22, 21])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HXDe8vGJCEn",
    "outputId": "053e9b69-fe86-42c8-f8d4-10de219c1369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([11]) the target: 1\n",
      "when input is tensor([11,  1]) the target: 39\n",
      "when input is tensor([11,  1, 39]) the target: 26\n",
      "when input is tensor([11,  1, 39, 26]) the target: 36\n",
      "when input is tensor([11,  1, 39, 26, 36]) the target: 26\n",
      "when input is tensor([11,  1, 39, 26, 36, 26]) the target: 37\n",
      "when input is tensor([11,  1, 39, 26, 36, 26, 37]) the target: 22\n",
      "when input is tensor([11,  1, 39, 26, 36, 26, 37, 22]) the target: 21\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3k1Czf7LuA9",
    "outputId": "a1724807-724c-4460-97ba-39c5e3cfed5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 37, 25, 26, 36,  1, 42, 22],\n",
      "        [ 1, 36, 40, 18, 42, 26, 31, 24],\n",
      "        [32, 23,  1, 18, 36, 37, 32, 31],\n",
      "        [36,  1, 37, 32,  1, 37, 25, 22]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[37, 25, 26, 36,  1, 42, 22, 18],\n",
      "        [36, 40, 18, 42, 26, 31, 24,  1],\n",
      "        [23,  1, 18, 36, 37, 32, 31, 26],\n",
      "        [ 1, 37, 32,  1, 37, 25, 22,  1]])\n",
      "----\n",
      "when input is [1] the target: 37\n",
      "when input is [1, 37] the target: 25\n",
      "when input is [1, 37, 25] the target: 26\n",
      "when input is [1, 37, 25, 26] the target: 36\n",
      "when input is [1, 37, 25, 26, 36] the target: 1\n",
      "when input is [1, 37, 25, 26, 36, 1] the target: 42\n",
      "when input is [1, 37, 25, 26, 36, 1, 42] the target: 22\n",
      "when input is [1, 37, 25, 26, 36, 1, 42, 22] the target: 18\n",
      "when input is [1] the target: 36\n",
      "when input is [1, 36] the target: 40\n",
      "when input is [1, 36, 40] the target: 18\n",
      "when input is [1, 36, 40, 18] the target: 42\n",
      "when input is [1, 36, 40, 18, 42] the target: 26\n",
      "when input is [1, 36, 40, 18, 42, 26] the target: 31\n",
      "when input is [1, 36, 40, 18, 42, 26, 31] the target: 24\n",
      "when input is [1, 36, 40, 18, 42, 26, 31, 24] the target: 1\n",
      "when input is [32] the target: 23\n",
      "when input is [32, 23] the target: 1\n",
      "when input is [32, 23, 1] the target: 18\n",
      "when input is [32, 23, 1, 18] the target: 36\n",
      "when input is [32, 23, 1, 18, 36] the target: 37\n",
      "when input is [32, 23, 1, 18, 36, 37] the target: 32\n",
      "when input is [32, 23, 1, 18, 36, 37, 32] the target: 31\n",
      "when input is [32, 23, 1, 18, 36, 37, 32, 31] the target: 26\n",
      "when input is [36] the target: 1\n",
      "when input is [36, 1] the target: 37\n",
      "when input is [36, 1, 37] the target: 32\n",
      "when input is [36, 1, 37, 32] the target: 1\n",
      "when input is [36, 1, 37, 32, 1] the target: 37\n",
      "when input is [36, 1, 37, 32, 1, 37] the target: 25\n",
      "when input is [36, 1, 37, 32, 1, 37, 25] the target: 22\n",
      "when input is [36, 1, 37, 32, 1, 37, 25, 22] the target: 1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpyyAeIzQjlO",
    "outputId": "7cbd2350-07f0-4fd8-8f77-23dc74c76951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 37, 25, 26, 36,  1, 42, 22],\n",
      "        [ 1, 36, 40, 18, 42, 26, 31, 24],\n",
      "        [32, 23,  1, 18, 36, 37, 32, 31],\n",
      "        [36,  1, 37, 32,  1, 37, 25, 22]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nql_1ER53oCf",
    "outputId": "6b7df8c7-50c9-4e1f-c682-a79dad215748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 44])\n",
      "tensor(4.2122, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "dbR\n",
      "AS.,tn.ocrxevAu'nS.gMvF'drFM\n",
      "vTn.fTgjnbBaIFS.cRilre.vav,bB.oFh-S.axwUkAreFtgu,MUs rSuu''o ArvrRi\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTyJ8qAaDdiF"
   },
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs4kI8YdEkQj",
    "outputId": "f5cb785a-359a-4e61-e97a-bdc0a2c2becd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.197262287139893\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcVIDWAZEtjN",
    "outputId": "16512bcd-28de-4d0b-a181-da04682a9ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "edmoqOIlSthM-uS\n",
      "MohFtB'oxRzHbRIgsFH.MxUucrGtBazS.Fp,dGyeAu'ipAOrzbUn\n",
      "S. HgahRdUHvkvIorgc,\n",
      "mhn-nHxdrrttHsGUwcsFuvex kh,OpTAz.HlFsqO\n",
      "S.OIT-FassAqoetH SwtHmy-a.cd\n",
      "nrTyfgfsc GhTzkvargsF'sqb.Iw\n",
      "qvH-FFS.vHauymoi spITfohF'yveocAhlalF G-aSp, GxreI-btMq,nAxIFBS. s.rj AHugs\n",
      "S.rxe GhUq'ocqbyrGAMmyr' GqvH-iGgvplxaqbrgbqR\n",
      "nqBSamejnSs.bTgG\n",
      "SwTgtFg HHwrFGxhrGxiBah-OIRilgtphspIOyvARlBnBSIoHzhRBrTgmRvhwrxu,\n",
      "nrb,MbR\n",
      "n,ns k'xTguyr,pROfTFvr'rOftFFB\n",
      "nyHa ahhltGUABBS.\n",
      "yrgsdMpihxrbymUylpcActuizS.sqMfT,pTB\n",
      "tTmAsqGx, sq\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XinV8nmAnmKN"
   },
   "source": [
    "## The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tukiH-NbRBhA",
    "outputId": "0243a227-2404-444f-f24a-72ac04e68cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs_E24uRE8kr",
    "outputId": "89d75b47-cd79-4ec5-d760-91cf7fc9a1c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86NuXX0fn7ps"
   },
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhdOAd6-wXkZ",
    "outputId": "81b0dcb7-56ba-4ddf-93fb-880bf140dfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOURrfG-ysoL",
    "outputId": "a782cae7-f839-4792-bb68-ba90245f4258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDarxEWIRMKq",
    "outputId": "74183e27-7d5a-4dc3-d8ec-d094b3a5a384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT1hdtzXCjgL",
    "outputId": "392f1585-cc04-4df6-dd7e-aa5762eea6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5CvobiQ0pLr"
   },
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SNbLq5z3oBw"
   },
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl6I9n9IRTSo",
    "outputId": "af29dd27-e985-41a2-bba5-0afe5af1b4d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1tQx7oeRvtc",
    "outputId": "78ebf32a-f1d4-4b06-e0ce-74981c0d185d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLb_odHU3iKM",
    "outputId": "86867a10-02e1-4ca8-cd23-e312bf2d2b45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JB82yzt44REI",
    "outputId": "a9b7b45f-b4d1-4adc-e1f3-b936eb7f3c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpt8569BB9_f",
    "outputId": "aeea73b2-286d-4a65-a71c-a8aa7da0bf45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Num7sX9CKOH",
    "outputId": "7eac237e-712b-4b3a-e47f-a4c9466129b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633T2cmnW1uk",
    "outputId": "a4c35aae-2473-43db-c0fd-cf439517abc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN9cK9BoXCYb",
    "outputId": "a4377f8e-ddc0-477b-9fdb-db9dbb202e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRJH6wM_XFfU"
   },
   "outputs": [],
   "source": [
    "# French to English translation example:\n",
    "\n",
    "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
    "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcvKeBXoZFOY"
   },
   "source": [
    "### Full finished code, for reference\n",
    "\n",
    "You may want to refer directly to the git repo instead though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "5e8183c0-0fa4-4177-84ae-2072cdcc1b4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20702 M parameters\n",
      "step 0: train loss 3.8550, val loss 3.8628\n",
      "step 50: train loss 2.5477, val loss 2.5837\n",
      "step 100: train loss 2.3986, val loss 2.4729\n",
      "step 150: train loss 2.3200, val loss 2.4507\n",
      "step 200: train loss 2.2653, val loss 2.4210\n",
      "step 250: train loss 2.1779, val loss 2.3862\n",
      "step 300: train loss 2.0855, val loss 2.3259\n",
      "step 350: train loss 1.9538, val loss 2.3579\n",
      "step 400: train loss 1.8035, val loss 2.3363\n",
      "step 450: train loss 1.6604, val loss 2.3881\n",
      "step 499: train loss 1.4750, val loss 2.4340\n",
      "\n",
      "\n",
      "\n",
      "SIled meling ounur j anaturf\n",
      "\n",
      "I the tave phestnceje. The Merovels thictanint f, healinve aspincessednc cendlurque. Gea Syilsptlm-, hearity ddre-chtraly's wanercitedly. The I vitcaned lbealespes red henchentrine's tef ourinng chise wite swigh anthan ssplpedy enescped the stthe tlue wander the ilndaeni rinisalped to wable the ai, eniocint lanan figanesting culliline, withrie wost aldrr wem by whe the tacontank rapec nforivef tsel's, wit-t-drery, wibonthe actedlic fidllive lbe dexpesti-ce sheribed linneng waertuge culbredle. Me womph atrditB sureng brineat the mindlly wire bea. The totrUlomend the she henchints ereef Uuriede a of the tage sencuptrest pestuMenve'me shtr ant spanfoforlis the table azme stgoHlde, beachulypar criptus lthe tazas tand deexpeccisent pereche. The ve mof boranonl tand randiculind maband toatrand banalisc haniwor, phed pelisesred beachdly off soreng the gotaz che intand dulin shene, couls withe and colenenck foreahig k llmusenss wep-chet, turontindenby azurine. I of the acowilen oan f rlue madsenck mam spand tolenss glenve, she, efvibor andlyscthenc wentand the rigenggen hen tusan wopldererche pichous lxpand serecint brined lulang anagesp. The wibre antypticrulyss thed braghe ut uenchint sinencilures, plurictued wa spenc e. The Thant iinrilf, ilidenos. sopic eref anver thotabnd he orajnest eenirmble hedine heng buentylusrexpanched chessed lusikHocypenc ptresedenming ach wof culs with antderougy's thobre octhe ezfoul tres bedancher enched pafulamal dlonctand nd lexpeccouresed bypauges blphochil wen atend denselaHone's the Oghe guyspihr ta the bue wind lin crelbeau, and of the itracul toralil cullal arand d on offourabd dnanarwter ofin andshe tfvit angale. The chast and dinirrpest. Thoutr spr she vivdnt octmest be anand ong undensensploturned the bue wau provesend anfilys the ancaptuli. Aryse thenis cultyptros bosend bant and klede, atuchely suremine's ghtaj Amedve cralstable peAser plmesend incrician dyptu. Mesc Ophesawend ountht ldegel whe per\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 500\n",
    "eval_interval = 50\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# # wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "# with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "44DEO3FuKxp5",
    "outputId": "2f78e383-3804-45cc-8841-6de6c45dab21"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I visited Australia this year, a land of astonishing contrasts and spectacular beauty. Amidst the vast, sun-drenched landscapes, I found myself mesmerized by the rich tapestry of colors and textures. The azure skies stretched endlessly above, while the golden beaches sparkled under the radiant sun. I explored the lush, verdant rainforests, teeming with vibrant wildlife and exotic flora. The chorus of birdsong filled the air, creating a symphony of natural sounds that was both enchanting and soothing.In the heart of the country, I witnessed the majestic Uluru, a colossal red rock formation that rose dramatically from the flat, arid desert. Its sheer size and deep, fiery hues were a breathtaking sight, especially during sunset when the rock seemed to glow with an otherworldly light. The sacredness of this ancient landmark was palpable, and I felt a profound sense of awe and respect for the indigenous cultures that have revered it for millennia.As I traveled along the rugged coastline, I encountered picturesque, azure bays and serene, turquoise lagoons, each offering a unique and idyllic escape. The pristine, white sandy beaches were fringed with swaying palm trees, and the crystal-clear waters invited me to dive into an underwater paradise. The Great Barrier Reef, a kaleidoscopic wonderland of corals and marine life, was an unforgettable experience. The myriad of colors and the graceful dance of the fish amidst the corals were a testament to the beauty and fragility of our natural world.In the bustling, cosmopolitan cities, I was captivated by the vibrant, multicultural atmosphere. Sydney, with its iconic Opera House and stunning harbor, was a feast for the eyes. The city's architectural marvels juxtaposed with the serene beauty of the botanical gardens created a harmonious blend of urban and natural landscapes. Melbourne's art-filled laneways, brimming with creative energy, showcased the country's thriving cultural scene. The aromatic scents of diverse cuisines wafted through the air, inviting me to indulge in a culinary adventure.The Australian wildlife was another highlight of my journey. From the adorable, cuddly koalas perched high in the eucalyptus trees to the bounding kangaroos in the bushland, each encounter was a delightful surprise. The vibrant, iridescent plumage of the parrots and the elusive, nocturnal wombat added to the enchantment of the Australian fauna.Throughout my travels, the warmth and friendliness of the Australian people were ever-present. Their laid-back, welcoming nature made me feel at home in this distant land. The stories and laughter shared with locals enriched my experience, leaving me with cherished memories and a deep appreciation for the diverse and captivating beauty of Australia.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab8RdTErKlOs",
    "outputId": "4fd6a48f-9be9-4bc4-ef6f-647077cb43fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI froustlil an expecerecampe. Thacapalies juntrysed pexfond the the raches ilu anandy. Thropos shazand k seatuneng beactusped undlypoopersysss chesss pecitcespectlped scic icheser bocuned ay kbaled a\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=200)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Oz4hzd-LqFR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"Hello, world!\"\n",
    "\n",
    "# Check if a GPU is available and use it; otherwise, use the CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Encode the input text using your model's tokenizer or character-to-index mapping (stoi)\n",
    "# Ensure that only characters present in 'stoi' are encoded\n",
    "encoded_input = [stoi[c] for c in input_text if c in stoi]\n",
    "\n",
    "# Convert the encoded input to a PyTorch tensor and move it to the specified device\n",
    "idx = torch.tensor([encoded_input], dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjjvMifYZf7x",
    "outputId": "85935648-c534-45fa-cf30-bd352048fea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: e, Probability: 0.3016\n",
      "Token: d, Probability: 0.1372\n",
      "Token: s, Probability: 0.1034\n",
      "Token:  , Probability: 0.0813\n",
      "Token: a, Probability: 0.0762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assume 'idx' is your input context tensor\n",
    "logits, _ = model(idx)  # Forward pass\n",
    "probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Analyze the distribution at a specific position (e.g., the last token)\n",
    "position = -1  # Last token in the sequence\n",
    "token_probs = probabilities[0, position].detach().cpu().numpy()\n",
    "\n",
    "# Example: Print the top 5 most likely tokens and their probabilities\n",
    "topk = 5\n",
    "topk_indices = np.argsort(token_probs)[-topk:][::-1]\n",
    "for i in topk_indices:\n",
    "    token = decode([i])\n",
    "    prob = token_probs[i]\n",
    "    print(f\"Token: {token}, Probability: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "id": "_Zsaz9vCMpfK",
    "outputId": "c4f7d3ab-efa9-4d10-cd17-fdab2d43b1af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Token  Probability\n",
      "0     r     0.286402\n",
      "1     o     0.261101\n",
      "2     u     0.127522\n",
      "3     h     0.096910\n",
      "4     i     0.074960\n",
      "5     e     0.035941\n",
      "6     t     0.035257\n",
      "7     a     0.027940\n",
      "8     m     0.010604\n",
      "9     l     0.009653\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_probabilities(model, idx, stoi, itos, top_k=10):\n",
    "    # Forward pass to get logits\n",
    "    logits, _ = model(idx)\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # Focus on the last time step\n",
    "    last_step_probs = probabilities[0, -1].detach().cpu().numpy()\n",
    "\n",
    "    # Get top K probabilities and corresponding tokens\n",
    "    topk_prob, topk_indices = torch.topk(probabilities[0, -1], top_k)\n",
    "    topk_prob = topk_prob.detach().cpu().numpy()\n",
    "    topk_tokens = [itos[i] for i in topk_indices.cpu().numpy()]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(topk_tokens, topk_prob, color='skyblue')\n",
    "    plt.xlabel('Tokens')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Top K Token Probabilities')\n",
    "    plt.show()\n",
    "\n",
    "    # Creating a table\n",
    "    prob_df = pd.DataFrame({'Token': topk_tokens, 'Probability': topk_prob})\n",
    "    print(prob_df)\n",
    "\n",
    "# Example usage:\n",
    "input_text = \"Example input\"\n",
    "encoded_input = [stoi[c] for c in input_text if c in stoi]\n",
    "idx = torch.tensor([encoded_input], dtype=torch.long).to(device)\n",
    "model.to(device)\n",
    "\n",
    "# Visualize probabilities\n",
    "visualize_probabilities(model, idx, stoi, itos, top_k=10)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
